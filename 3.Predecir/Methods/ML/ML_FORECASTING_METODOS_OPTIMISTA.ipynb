{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA WRANGLING - DEMAND CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4203414, 7)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ruta_archivo = r\"C:\\Users\\etorres.DERCOPARTS\\DERCO CHILE REPUESTOS SpA\\Planificación y abastecimiento - Documentos\\Planificación y Compras Anastasia\\Carga Historia de Venta\\2024-10 Ciclo Nov-24\\AFM\\Correccion Dispo\\Anastasia 2024.10.csv\"\n",
    "df = pd.read_csv(ruta_archivo, delimiter=',', decimal=',', encoding='utf-8').rename(columns={'Canal': 'Canal 3', 'Cantidad': 'Venta', 'idSKU': 'Ultimo Eslabón'})\n",
    "df['ID'] = df['Ultimo Eslabón'].astype(str) + df['Canal 3'].astype(str)\n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'], format='%Y-%m-%d')\n",
    "df = df.sort_values(by=['Ultimo Eslabón', 'Fecha']).reset_index(drop=True)\n",
    "pivot_table = df.pivot_table(index=['Ultimo Eslabón', 'Canal 3'], columns='Fecha', values='Venta', fill_value=0).reset_index()\n",
    "pivot_table = pivot_table[pivot_table.iloc[:, 2:].sum(axis=1) >= 2]\n",
    "ultima_fecha = pivot_table.columns[-1]\n",
    "primer_fecha = ultima_fecha - pd.DateOffset(months=23)\n",
    "ventas_ultimos_24_meses = pivot_table.loc[:, primer_fecha:ultima_fecha]\n",
    "intervalos = ventas_ultimos_24_meses.apply(lambda x: (x != 0).astype(int).diff().fillna(1).abs().sum(), axis=1)\n",
    "ventas_activas = (ventas_ultimos_24_meses != 0).sum(axis=1)\n",
    "pivot_table['ADI'] = intervalos / ventas_activas\n",
    "ventas_no_cero = ventas_ultimos_24_meses.replace(0, np.nan)\n",
    "pivot_table['CV²'] = (ventas_no_cero.std(axis=1) / ventas_no_cero.mean(axis=1)) ** 2\n",
    "def clasificar_demanda(row):\n",
    "    if row['ADI'] < 1.32 and row['CV²'] < 0.49: return 'Smooth'\n",
    "    elif row['ADI'] >= 1.32 and row['CV²'] < 0.49: return 'Intermittent'\n",
    "    elif row['ADI'] < 1.32 and row['CV²'] >= 0.49: return 'Erratic'\n",
    "    else: return 'Lumpy'\n",
    "pivot_table['Demand Type'] = pivot_table.apply(clasificar_demanda, axis=1)\n",
    "melted_data = pivot_table.melt(id_vars=['Ultimo Eslabón', 'Canal 3', 'ADI', 'CV²', 'Demand Type'], var_name='Fecha', value_name='Venta')\n",
    "melted_data['Fecha'] = pd.to_datetime(melted_data['Fecha'], format='%Y-%m-%d')\n",
    "data = melted_data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPCIONAL GUARDAR COMO EXCEL EL CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['ID'] = data['Ultimo Eslabón'].astype(str) + data['Canal 3']\n",
    "# data = data[['Ultimo Eslabón', 'ID', 'Demand Type']].drop_duplicates()\n",
    "# ruta_guardado = r\"C:\\Users\\etorres.DERCOPARTS\\DERCO CHILE REPUESTOS SpA\\Planificación y abastecimiento - Documentos\\Planificación y Compras Anastasia\\Carga Historia de Venta\\2024-10 Ciclo Nov-24\\AFM\\Correccion Dispo\\Cluster 2024.10.xlsx\"\n",
    "# data.to_excel(ruta_guardado, index=False)\n",
    "# data = melted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique counts of ID & Canal 3 per Demand Type:\n",
      "Demand Type\n",
      "Erratic          4379\n",
      "Intermittent     4328\n",
      "Lumpy           32655\n",
      "Smooth          10532\n",
      "dtype: int64\n",
      "\n",
      "Row counts per Demand Type:\n",
      "Demand Type\n",
      "Lumpy           2645055\n",
      "Smooth           853092\n",
      "Erratic          354699\n",
      "Intermittent     350568\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Temp\\ipykernel_24512\\1170459666.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  unique_counts = melted_data.groupby('Demand Type').apply(lambda x: x[['Ultimo Eslabón', 'Canal 3']].drop_duplicates().shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Contar el número de combinaciones únicas de 'Ultimo Eslabón' y 'Canal 3' para cada 'Demand Type'\n",
    "unique_counts = melted_data.groupby('Demand Type').apply(lambda x: x[['Ultimo Eslabón', 'Canal 3']].drop_duplicates().shape[0])\n",
    "\n",
    "# Contar el número de filas para cada 'Demand Type'\n",
    "filas_count = melted_data['Demand Type'].value_counts()\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Unique counts of ID & Canal 3 per Demand Type:\")\n",
    "print(unique_counts)\n",
    "\n",
    "print(\"\\nRow counts per Demand Type:\")\n",
    "print(filas_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA SMOOTH #PRESENTE VIRTUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ultimo Eslabón</th>\n",
       "      <th>Canal 3</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Venta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100480</td>\n",
       "      <td>CL RETAIL</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100483</td>\n",
       "      <td>CL RETAIL</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ultimo Eslabón    Canal 3      Fecha  Venta\n",
       "5          100480  CL RETAIL 2018-01-01  159.0\n",
       "9          100483  CL RETAIL 2018-01-01    0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = melted_data[melted_data['Demand Type'] == 'Erratic']\n",
    "data = data[['Ultimo Eslabón', 'Canal 3', 'Fecha', 'Venta']]\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ultimo Eslabón</th>\n",
       "      <th>Canal 3</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Venta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100481</td>\n",
       "      <td>CL RETAIL</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ultimo Eslabón    Canal 3      Fecha  Venta\n",
       "7          100481  CL RETAIL 2018-01-01   63.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(853092, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dividir el df en 2 partes para entrenar modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eslabones_unicos = data['Ultimo Eslabón'].unique()\n",
    "# mitad_eslabones = eslabones_unicos[:len(eslabones_unicos)//2]\n",
    "# data = data[data['Ultimo Eslabón'].isin(mitad_eslabones)]\n",
    "# data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA SMOOTH_OPTIMISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'C:\\Users\\etorres.DERCOPARTS\\DERCO CHILE REPUESTOS SpA\\Planificación y abastecimiento - Documentos\\Planificación y Compras AFM\\S&OP Demanda\\Codigos Demanda\\Scripts\\3.Predecir\\Methods\\ML'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDERCO CHILE REPUESTOS SpA\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPlanificación y abastecimiento - Documentos\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPlanificación y Compras AFM\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS&OP Demanda\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCodigos Demanda\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mScripts\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m3.Predecir\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMethods\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mML\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m output_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mARIMA_SMOOTH_normal_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_month\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_e1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m \u001b[43mpredictions_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\etorres.DERCOPARTS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'C:\\Users\\etorres.DERCOPARTS\\DERCO CHILE REPUESTOS SpA\\Planificación y abastecimiento - Documentos\\Planificación y Compras AFM\\S&OP Demanda\\Codigos Demanda\\Scripts\\3.Predecir\\Methods\\ML'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "data['ID'] = data.apply(lambda row: f\"{row['Ultimo Eslabón']}_{row['Canal 3']}\", axis=1)\n",
    "data['Fecha'] = pd.to_datetime(data['Fecha'], format='%Y-%m-%d')\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for id_value in data['ID'].unique():\n",
    "    data_id = data[data['ID'] == id_value]\n",
    "    data_id.set_index('Fecha', inplace=True, drop=True)\n",
    "    data_id.index.freq = 'MS'\n",
    "    y = data_id['Venta']\n",
    "    \n",
    "    if y.isnull().any() or np.isinf(y).any():\n",
    "        print(f'Serie temporal con valores nulos o infinitos para ID: {id_value}')\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        model = ARIMA(y, order=(5, 1, 0))\n",
    "        model_fit = model.fit()\n",
    "        future_predictions = model_fit.forecast(steps=12)\n",
    "        future_dates = pd.date_range(start='2024-11-01', periods=12, freq='MS').strftime('%Y-%m-%d')\n",
    "        \n",
    "        for date, pred in zip(future_dates, future_predictions):\n",
    "            predictions.append({\n",
    "                'ID': id_value,\n",
    "                'Fecha': date,\n",
    "                'Prediccion_Venta': pred\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f'Error al ajustar el modelo para ID: {id_value} - {e}')\n",
    "        continue\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "current_month = datetime.now().strftime('%Y-%m')\n",
    "output_dir = os.path.expanduser(r'~\\DERCO CHILE REPUESTOS SpA\\Planificación y abastecimiento - Documentos\\Planificación y Compras AFM\\S&OP Demanda\\Codigos Demanda\\Scripts\\3.Predecir\\Methods\\ML')\n",
    "output_file = os.path.join(output_dir, f'ARIMA_SMOOTH_normal_{current_month}_e1.csv')\n",
    "predictions_df.to_csv(output_file, index=False, sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.expanduser(r'~\\DERCO CHILE REPUESTOS SpA\\Planificación y abastecimiento - Documentos\\Planificación y Compras AFM\\S&OP Demanda\\Codigos Demanda')\n",
    "output_file = os.path.join(output_dir, f'ARIMA_SMOOTH_normal_{current_month}_e1.csv')\n",
    "predictions_df.to_csv(output_file, index=False, sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#AUTO ARIMA SMOOTH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "# import os\n",
    "# from pmdarima import auto_arima\n",
    "# from datetime import datetime\n",
    "# from numpy.linalg import LinAlgError\n",
    "# import warnings\n",
    "\n",
    "# # Supongamos que 'data' es tu DataFrame inicial\n",
    "# # Asegúrate de que 'data' tenga las columnas 'Ultimo Eslabón', 'Canal 3', 'Fecha' y 'Venta'\n",
    "\n",
    "# # Crear el ID único combinando 'Ultimo Eslabón' y 'Canal 3'\n",
    "# data['ID'] = data.apply(lambda row: f\"{row['Ultimo Eslabón']}_{row['Canal 3']}\", axis=1)\n",
    "# data['Fecha'] = pd.to_datetime(data['Fecha'], format='%Y-%m-%d')\n",
    "\n",
    "# predictions = []\n",
    "\n",
    "# # Iterar sobre cada ID único\n",
    "# for id_value in data['ID'].unique():\n",
    "#     data_id = data[data['ID'] == id_value].copy()\n",
    "#     data_id.set_index('Fecha', inplace=True)\n",
    "    \n",
    "#     # Ordenar el índice y verificar la frecuencia\n",
    "#     data_id = data_id.sort_index()\n",
    "#     data_id = data_id.asfreq('MS')  # Asegura frecuencia mensual\n",
    "    \n",
    "#     y = data_id['Venta']\n",
    "    \n",
    "#     # Verificar si hay datos insuficientes\n",
    "#     if y.isnull().all() or len(y.dropna()) < 3:\n",
    "#         # Proyectar 0 si no hay datos suficientes\n",
    "#         future_dates = pd.date_range(start='2024-10-01', periods=12, freq='MS')\n",
    "#         for date in future_dates:\n",
    "#             predictions.append({\n",
    "#                 'ID': id_value,\n",
    "#                 'Fecha': date.strftime('%Y-%m-%d'),\n",
    "#                 'Prediccion_Venta': 0\n",
    "#             })\n",
    "#         continue\n",
    "    \n",
    "#     # Manejo de errores y advertencias\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.filterwarnings(\"ignore\")\n",
    "#         try:\n",
    "#             # Ajustar el modelo ARIMA\n",
    "#             model = auto_arima(\n",
    "#                 y,\n",
    "#                 start_p=0, max_p=3,\n",
    "#                 start_q=0, max_q=3,\n",
    "#                 seasonal=False,\n",
    "#                 stepwise=True,\n",
    "#                 suppress_warnings=True,\n",
    "#                 error_action='ignore',\n",
    "#                 trace=False\n",
    "#             )\n",
    "#             # Predecir los próximos 12 meses\n",
    "#             future_predictions = model.predict(n_periods=12)\n",
    "#             future_dates = pd.date_range(start='2024-10-01', periods=12, freq='MS')\n",
    "            \n",
    "#             for date, pred in zip(future_dates, future_predictions):\n",
    "#                 predictions.append({\n",
    "#                     'ID': id_value,\n",
    "#                     'Fecha': date.strftime('%Y-%m-%d'),\n",
    "#                     'Prediccion_Venta': max(0, pred)  # Asegurar que la predicción no sea negativa\n",
    "#                 })\n",
    "#         except (LinAlgError, ValueError, Exception):\n",
    "#             # Si ocurre un error, proyectar 0 para los próximos 12 meses\n",
    "#             future_dates = pd.date_range(start='2024-10-01', periods=12, freq='MS')\n",
    "#             for date in future_dates:\n",
    "#                 predictions.append({\n",
    "#                     'ID': id_value,\n",
    "#                     'Fecha': date.strftime('%Y-%m-%d'),\n",
    "#                     'Prediccion_Venta': 0\n",
    "#                 })\n",
    "#             continue\n",
    "\n",
    "# # Crear el DataFrame de predicciones\n",
    "# predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# # Guardar el archivo CSV\n",
    "# current_month = datetime.now().strftime('%Y-%m')\n",
    "# output_dir = os.path.expanduser(r'~\\DERCO CHILE REPUESTOS SpA\\Planificación y abastecimiento - Documentos\\Planificación y Compras AFM\\S&OP Demanda\\Codigos Demanda\\Scripts\\3.Predecir\\Methods\\ML')\n",
    "# output_file = os.path.join(output_dir, f'ARIMA_SMOOTH_AUTO_O1{current_month}.csv')\n",
    "\n",
    "# # Asegurarse de que el directorio existe\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Guardar las predicciones en un archivo CSV\n",
    "# predictions_df.to_csv(output_file, index=False, sep=';', decimal=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA - ERRATIC - PRESENTE VIRTUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = melted_data[melted_data['Demand Type'] == 'Erratic']\n",
    "data = data[['Ultimo Eslabón', 'Canal 3', 'Fecha', 'Venta']]\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTO_ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "# import os\n",
    "# from pmdarima import auto_arima\n",
    "# from datetime import datetime\n",
    "\n",
    "# data['ID'] = data.apply(lambda row: f\"{row['Ultimo Eslabón']}_{row['Canal 3']}\", axis=1)\n",
    "# data['Fecha'] = pd.to_datetime(data['Fecha'], format='%Y-%m-%d')\n",
    "\n",
    "# predictions = []\n",
    "\n",
    "# for id_value in data['ID'].unique():\n",
    "#     data_id = data[data['ID'] == id_value]\n",
    "#     data_id.set_index('Fecha', inplace=True, drop=True)\n",
    "#     data_id.index.freq = 'MS'\n",
    "#     y = data_id['Venta']\n",
    "    \n",
    "#     if y.isnull().any() or np.isinf(y).any():\n",
    "#         continue\n",
    "    \n",
    "#     try:\n",
    "#         model = auto_arima(y, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "#         future_predictions = model.predict(n_periods=12)\n",
    "#         future_dates = pd.date_range(start='2024-10-01', periods=12, freq='MS').strftime('%Y-%m-%d')\n",
    "        \n",
    "#         for date, pred in zip(future_dates, future_predictions):\n",
    "#             predictions.append({\n",
    "#                 'ID': id_value,\n",
    "#                 'Fecha': date,\n",
    "#                 'Prediccion_Venta': pred\n",
    "#             })\n",
    "#     except Exception:\n",
    "#         continue\n",
    "\n",
    "# predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# current_month = datetime.now().strftime('%Y-%m')\n",
    "# output_dir = os.path.expanduser(r'~\\DERCO CHILE REPUESTOS SpA\\Planificación y abastecimiento - Documentos\\Planificación y Compras AFM\\S&OP Demanda\\Codigos Demanda\\Scripts\\3.Predecir\\Methods\\ML')\n",
    "# output_file = os.path.join(output_dir, f'AUTO_ARIMA_ERRATIC_{current_month}.csv')\n",
    "\n",
    "# predictions_df.to_csv(output_file, index=False, sep=';', decimal=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "data['ID'] = data.apply(lambda row: f\"{row['Ultimo Eslabón']}_{row['Canal 3']}\", axis=1)\n",
    "data['Fecha'] = pd.to_datetime(data['Fecha'], format='%Y-%m-%d')\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for id_value in data['ID'].unique():\n",
    "    data_id = data[data['ID'] == id_value]\n",
    "    data_id.set_index('Fecha', inplace=True, drop=True)\n",
    "    data_id.index.freq = 'MS'\n",
    "    y = data_id['Venta']\n",
    "    \n",
    "    if y.isnull().any() or np.isinf(y).any():\n",
    "        print(f'Serie temporal con valores nulos o infinitos para ID: {id_value}')\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        model = ARIMA(y, order=(5, 1, 0))\n",
    "        model_fit = model.fit()\n",
    "        future_predictions = model_fit.forecast(steps=12)\n",
    "        future_dates = pd.date_range(start='2024-11-01', periods=12, freq='MS').strftime('%Y-%m-%d')\n",
    "        \n",
    "        for date, pred in zip(future_dates, future_predictions):\n",
    "            predictions.append({\n",
    "                'ID': id_value,\n",
    "                'Fecha': date,\n",
    "                'Prediccion_Venta': pred\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f'Error al ajustar el modelo para ID: {id_value} - {e}')\n",
    "        continue\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "current_month = datetime.now().strftime('%Y-%m')\n",
    "output_dir = os.path.expanduser(r'~\\DERCO CHILE REPUESTOS SpA\\Planificación y abastecimiento - Documentos\\Planificación y Compras AFM\\S&OP Demanda\\Codigos Demanda\\Scripts\\3.Predecir\\Methods\\ML')\n",
    "output_file = os.path.join(output_dir, f'ARIMA_SMOOTH_Erratic_{current_month}_1.csv')\n",
    "\n",
    "predictions_df.to_csv(output_file, index=False, sep=';', decimal=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA INTTERMITENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = melted_data[melted_data['Demand Type'] == 'Intermittent']\n",
    "data = data[['Ultimo Eslabón', 'Canal 3', 'Fecha', 'Venta']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "data['ID'] = data.apply(lambda row: f\"{row['Ultimo Eslabón']}_{row['Canal 3']}\", axis=1)\n",
    "data['Fecha'] = pd.to_datetime(data['Fecha'], format='%Y-%m-%d')\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for id_value in data['ID'].unique():\n",
    "    data_id = data[data['ID'] == id_value]\n",
    "    data_id.set_index('Fecha', inplace=True, drop=True)\n",
    "    data_id.index.freq = 'MS'\n",
    "    y = data_id['Venta']\n",
    "    \n",
    "    if y.isnull().any() or np.isinf(y).any():\n",
    "        print(f'Serie temporal con valores nulos o infinitos para ID: {id_value}')\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        model = ARIMA(y, order=(5, 1, 0))\n",
    "        model_fit = model.fit()\n",
    "        future_predictions = model_fit.forecast(steps=12)\n",
    "        future_dates = pd.date_range(start='2024-11-01', periods=12, freq='MS').strftime('%Y-%m-%d')\n",
    "        \n",
    "        for date, pred in zip(future_dates, future_predictions):\n",
    "            predictions.append({\n",
    "                'ID': id_value,\n",
    "                'Fecha': date,\n",
    "                'Prediccion_Venta': pred\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f'Error al ajustar el modelo para ID: {id_value} - {e}')\n",
    "        continue\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "current_month = datetime.now().strftime('%Y-%m')\n",
    "output_dir = os.path.expanduser(r'~\\DERCO CHILE REPUESTOS SpA\\Planificación y abastecimiento - Documentos\\Planificación y Compras AFM\\S&OP Demanda\\Codigos Demanda\\Scripts\\3.Predecir\\Methods\\ML')\n",
    "output_file = os.path.join(output_dir, f'ARIMA_SMOOTH_Intermittent_{current_month}_1.csv')\n",
    "\n",
    "predictions_df.to_csv(output_file, index=False, sep=';', decimal=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSTON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = melted_data[melted_data['Demand Type'] == 'Intermittent']\n",
    "# data = data[['Ultimo Eslabón', 'Canal 3', 'Fecha', 'Venta']]\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# def croston(ts, alpha=0.4, h=12):\n",
    "#     ts = np.array(ts)\n",
    "#     n = len(ts)\n",
    "#     a, p = np.zeros(n), np.zeros(n)\n",
    "#     q = np.zeros(n)\n",
    "#     y_hat = np.zeros(n + h)\n",
    "#     a[0], p[0], q[0] = ts[0], 1, ts[0]\n",
    "    \n",
    "#     for t in range(1, n):\n",
    "#         if ts[t] > 0:\n",
    "#             p[t] = alpha * ts[t] + (1 - alpha) * p[t - 1]\n",
    "#             q[t] = alpha * (t - a[t - 1]) + (1 - alpha) * q[t - 1]\n",
    "#             a[t] = t\n",
    "#         else:\n",
    "#             p[t] = p[t - 1]\n",
    "#             q[t] = q[t - 1]\n",
    "#             a[t] = a[t - 1]\n",
    "    \n",
    "#     for t in range(n, n + h):\n",
    "#         y_hat[t] = p[-1] / q[-1]\n",
    "    \n",
    "#     return y_hat[-h:]\n",
    "\n",
    "# # Asegúrate de que 'data' es un DataFrame original y no una vista de otro DataFrame\n",
    "# data = data.copy()\n",
    "\n",
    "# # Crear la columna 'ID' usando .loc para evitar el SettingWithCopyWarning\n",
    "# data.loc[:, 'ID'] = data.apply(lambda row: f\"{row['Ultimo Eslabón']}_{row['Canal 3']}\", axis=1)\n",
    "\n",
    "# # Convertir la columna 'Fecha' al formato datetime usando .loc\n",
    "# data.loc[:, 'Fecha'] = pd.to_datetime(data['Fecha'], format='%Y-%m-%d')\n",
    "\n",
    "# predictions = []\n",
    "\n",
    "# # Simulamos estar en diciembre de 2023 pero queremos predecir a partir de enero de 2024\n",
    "# for id_value in data['ID'].unique():\n",
    "#     data_id = data[data['ID'] == id_value].copy()  # Asegurarse de trabajar con una copia del DataFrame\n",
    "#     data_id.set_index('Fecha', inplace=True, drop=True)\n",
    "#     data_id.index.freq = 'MS'  # Esto supone que las fechas son mensuales y consecutivas\n",
    "#     y = data_id['Venta']\n",
    "    \n",
    "#     if y.isnull().any() or np.isinf(y).any():\n",
    "#         print(f'Serie temporal con valores nulos o infinitos para ID: {id_value}')\n",
    "#         continue\n",
    "    \n",
    "#     try:\n",
    "#         # Aplicar el método de Croston\n",
    "#         future_predictions = croston(y.values, alpha=0.4, h=12)\n",
    "        \n",
    "#         # Crear las fechas de predicción a partir de enero de 2024\n",
    "#         future_dates = pd.date_range(start='2024-01-01', periods=12, freq='MS').strftime('%Y-%m-%d')\n",
    "        \n",
    "#         for date, pred in zip(future_dates, future_predictions):\n",
    "#             predictions.append({\n",
    "#                 'ID': id_value,\n",
    "#                 'Fecha': date,\n",
    "#                 'Prediccion_Venta': pred\n",
    "#             })\n",
    "#     except Exception as e:\n",
    "#         print(f'Error al ajustar el modelo para ID: {id_value} - {e}')\n",
    "#         continue\n",
    "\n",
    "# predictions_df = pd.DataFrame(predictions)\n",
    "# output_dir = r'C:\\Users\\etorres.DERCOPARTS\\DERCO CHILE REPUESTOS SpA\\Planificación y abastecimiento - Documentos\\Planificación y Compras AFM\\S&OP Demanda\\Codigos Demanda\\Scripts\\Ciclo'\n",
    "# output_file = os.path.join(output_dir, 'CROSTON_INTERMITTENT.csv')\n",
    "# predictions_df.to_csv(output_file, index=False, sep=';', decimal=',')\n",
    "\n",
    "# print(f'Predicciones guardadas en {output_file}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
